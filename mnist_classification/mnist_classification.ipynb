{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f82cd4c1-bb15-4396-822c-189c873fb7e0",
   "metadata": {},
   "source": [
    "# Handwritten number classification\n",
    "\n",
    "This exercise uses ML algorithms to classify handwritten numbers. This exercise uses the popular MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a88c11d4-c17f-425d-ae35-53e04b685c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sklearn package has some useful methods to fetch many different datasets.\n",
    "# By default, these are stored in $HOME/scikit_learn_data/\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', parser='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e9319cb-cd9e-4a58-8a85-1f085683b2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Author**: Yann LeCun, Corinna Cortes, Christopher J.C. Burges  \n",
      "**Source**: [MNIST Website](http://yann.lecun.com/exdb/mnist/) - Date unknown  \n",
      "**Please cite**:  \n",
      "\n",
      "The MNIST database of handwritten digits with 784 features, raw data available at: http://yann.lecun.com/exdb/mnist/. It can be split in a training set of the first 60,000 examples, and a test set of 10,000 examples  \n",
      "\n",
      "It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting. The original black and white (bilevel) images from NIST were size normalized to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting images contain grey levels as a result of the anti-aliasing technique used by the normalization algorithm. the images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field.  \n",
      "\n",
      "With some classification methods (particularly template-based methods, such as SVM and K-nearest neighbors), the error rate improves when the digits are centered by bounding box rather than center of mass. If you do this kind of pre-processing, you should report it in your publications. The MNIST database was constructed from NIST's NIST originally designated SD-3 as their training set and SD-1 as their test set. However, SD-3 is much cleaner and easier to recognize than SD-1. The reason for this can be found on the fact that SD-3 was collected among Census Bureau employees, while SD-1 was collected among high-school students. Drawing sensible conclusions from learning experiments requires that the result be independent of the choice of training set and test among the complete set of samples. Therefore it was necessary to build a new database by mixing NIST's datasets.  \n",
      "\n",
      "The MNIST training set is composed of 30,000 patterns from SD-3 and 30,000 patterns from SD-1. Our test set was composed of 5,000 patterns from SD-3 and 5,000 patterns from SD-1. The 60,000 pattern training set contained examples from approximately 250 writers. We made sure that the sets of writers of the training set and test set were disjoint. SD-1 contains 58,527 digit images written by 500 different writers. In contrast to SD-3, where blocks of data from each writer appeared in sequence, the data in SD-1 is scrambled. Writer identities for SD-1 is available and we used this information to unscramble the writers. We then split SD-1 in two: characters written by the first 250 writers went into our new training set. The remaining 250 writers were placed in our test set. Thus we had two sets with nearly 30,000 examples each. The new training set was completed with enough examples from SD-3, starting at pattern # 0, to make a full set of 60,000 training patterns. Similarly, the new test set was completed with SD-3 examples starting at pattern # 35,000 to make a full set with 60,000 test patterns. Only a subset of 10,000 test images (5,000 from SD-1 and 5,000 from SD-3) is available on this site. The full 60,000 sample training set is available.\n",
      "\n",
      "Downloaded from openml.org.\n"
     ]
    }
   ],
   "source": [
    "print(mnist.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36b8a6d9-d37b-4331-8434-46e14ff6205b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '554',\n",
       " 'name': 'mnist_784',\n",
       " 'version': '1',\n",
       " 'description_version': '1',\n",
       " 'format': 'ARFF',\n",
       " 'creator': ['Yann LeCun', 'Corinna Cortes', 'Christopher J.C. Burges'],\n",
       " 'upload_date': '2014-09-29T03:28:38',\n",
       " 'language': 'English',\n",
       " 'licence': 'Public',\n",
       " 'url': 'https://api.openml.org/data/v1/download/52667/mnist_784.arff',\n",
       " 'parquet_url': 'http://openml1.win.tue.nl/dataset554/dataset_554.pq',\n",
       " 'file_id': '52667',\n",
       " 'default_target_attribute': 'class',\n",
       " 'tag': ['AzurePilot',\n",
       "  'OpenML-CC18',\n",
       "  'OpenML100',\n",
       "  'study_1',\n",
       "  'study_123',\n",
       "  'study_41',\n",
       "  'study_99',\n",
       "  'vision'],\n",
       " 'visibility': 'public',\n",
       " 'minio_url': 'http://openml1.win.tue.nl/dataset554/dataset_554.pq',\n",
       " 'status': 'active',\n",
       " 'processing_date': '2020-11-20 20:12:09',\n",
       " 'md5_checksum': '0298d579eb1b86163de7723944c7e495'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1075726c-00b8-4972-8aa4-2781a2638ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = mnist.data, mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b9c1b30-ef71-467c-a0e3-469c5347b90d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the data.\n",
    "# One row per instance and one column per feature.\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c0cc57-bdac-4079-81c2-7c2cf6435b13",
   "metadata": {},
   "source": [
    "- there are 70k images with 784 pixels each\n",
    "- $28 \\times 28 = 784$ pixels\n",
    "- resolution = 28x28 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90f28702-54d0-4fb2-b8a2-db984a3bab12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2568306-49d9-4e13-b747-ff22637dde87",
   "metadata": {},
   "source": [
    "- the `target` attribute contains an array on labels\n",
    "- it has the same number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79abe174-3709-4c0e-a4db-28f892aa4050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4f93acd5a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "digit = np.array(X.iloc[12345]).reshape(28, 28)\n",
    "\n",
    "plt.imshow(digit, cmap=matplotlib.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60921693-c176-45da-b3f7-4222bbcb7e38",
   "metadata": {},
   "source": [
    "# Split test and validation data\n",
    "\n",
    "Its important to split the data into a test and a training dataset. The first 60k images will ne used for training and the last 10k for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76302b06-f5dd-4035-b48c-8804df78699f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation = X.iloc[:60_000], X.iloc[60_000:]\n",
    "Y_train, Y_validation = Y.iloc[:60_000], Y.iloc[60_000:]\n",
    "\n",
    "# Delete the old datasets in order to prevent me from using them accidentally\n",
    "del X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17de0b4a-90f1-41e1-ba8d-d9ff040bd940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0: 5\n",
      "Index 500: 3\n",
      "Index 1000: 0\n",
      "Index 1500: 9\n",
      "Index 2000: 5\n",
      "Index 2500: 0\n",
      "Index 3000: 9\n",
      "Index 3500: 5\n",
      "Index 4000: 7\n",
      "Index 4500: 0\n",
      "Index 5000: 7\n",
      "Index 5500: 1\n",
      "Index 6000: 6\n",
      "Index 6500: 3\n",
      "Index 7000: 8\n",
      "Index 7500: 2\n",
      "Index 8000: 0\n",
      "Index 8500: 6\n",
      "Index 9000: 6\n",
      "Index 9500: 6\n",
      "Index 10000: 3\n",
      "Index 10500: 1\n",
      "Index 11000: 6\n",
      "Index 11500: 5\n",
      "Index 12000: 7\n",
      "Index 12500: 0\n",
      "Index 13000: 7\n",
      "Index 13500: 4\n",
      "Index 14000: 1\n",
      "Index 14500: 6\n",
      "Index 15000: 5\n",
      "Index 15500: 6\n",
      "Index 16000: 8\n",
      "Index 16500: 8\n",
      "Index 17000: 3\n",
      "Index 17500: 2\n",
      "Index 18000: 4\n",
      "Index 18500: 9\n",
      "Index 19000: 8\n",
      "Index 19500: 3\n",
      "Index 20000: 5\n",
      "Index 20500: 3\n",
      "Index 21000: 7\n",
      "Index 21500: 4\n",
      "Index 22000: 3\n",
      "Index 22500: 2\n",
      "Index 23000: 7\n",
      "Index 23500: 6\n",
      "Index 24000: 8\n",
      "Index 24500: 7\n",
      "Index 25000: 3\n",
      "Index 25500: 7\n",
      "Index 26000: 4\n",
      "Index 26500: 7\n",
      "Index 27000: 5\n",
      "Index 27500: 5\n",
      "Index 28000: 1\n",
      "Index 28500: 4\n",
      "Index 29000: 2\n",
      "Index 29500: 2\n",
      "Index 30000: 3\n",
      "Index 30500: 9\n",
      "Index 31000: 6\n",
      "Index 31500: 6\n",
      "Index 32000: 8\n",
      "Index 32500: 6\n",
      "Index 33000: 3\n",
      "Index 33500: 3\n",
      "Index 34000: 4\n",
      "Index 34500: 8\n",
      "Index 35000: 1\n",
      "Index 35500: 5\n",
      "Index 36000: 9\n",
      "Index 36500: 9\n",
      "Index 37000: 4\n",
      "Index 37500: 7\n",
      "Index 38000: 8\n",
      "Index 38500: 4\n",
      "Index 39000: 9\n",
      "Index 39500: 7\n",
      "Index 40000: 7\n",
      "Index 40500: 7\n",
      "Index 41000: 5\n",
      "Index 41500: 6\n",
      "Index 42000: 1\n",
      "Index 42500: 9\n",
      "Index 43000: 9\n",
      "Index 43500: 1\n",
      "Index 44000: 0\n",
      "Index 44500: 7\n",
      "Index 45000: 3\n",
      "Index 45500: 2\n",
      "Index 46000: 9\n",
      "Index 46500: 3\n",
      "Index 47000: 0\n",
      "Index 47500: 4\n",
      "Index 48000: 4\n",
      "Index 48500: 3\n",
      "Index 49000: 4\n",
      "Index 49500: 0\n",
      "Index 50000: 3\n",
      "Index 50500: 3\n",
      "Index 51000: 7\n",
      "Index 51500: 7\n",
      "Index 52000: 6\n",
      "Index 52500: 9\n",
      "Index 53000: 5\n",
      "Index 53500: 2\n",
      "Index 54000: 5\n",
      "Index 54500: 5\n",
      "Index 55000: 1\n",
      "Index 55500: 1\n",
      "Index 56000: 1\n",
      "Index 56500: 7\n",
      "Index 57000: 0\n",
      "Index 57500: 2\n",
      "Index 58000: 2\n",
      "Index 58500: 0\n",
      "Index 59000: 6\n",
      "Index 59500: 3\n"
     ]
    }
   ],
   "source": [
    "# The numbers are unordered\n",
    "for index in range(0, len(Y_train), 500):\n",
    "    print(f'Index {index}: {Y_train.iloc[index]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa37163-52d6-43c9-9c0d-3a4beb94b42c",
   "metadata": {},
   "source": [
    "# Multiclass Classification\n",
    "\n",
    "- **binary classifiers** (SGD) can distinguish two classes (e.g. 7 or 3)\n",
    "- **multiclass classifiers** can distinguish multiple classes\n",
    "- the **one-versus-all** strategy means to use **N** binary classifiers for this purpose\n",
    "  - for 10 numbers train 10 binary classifiers -> one for each number\n",
    "  - then for each number compute the decision score for each classifier\n",
    "  - finally, select the class with the highest score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a7c9b67-df78-4ffc-b8f4-0fd8823459e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDClassifier(random_state=42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Create an instance of the SGDClassifier\n",
    "clf = SGDClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier on the training data.\n",
    "# Scikit automaitcally detects that I want to perform multiclass classification.\n",
    "# The selects one-versus-all strategy by default\n",
    "clf.fit(X_train.values, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc3c90ef-dc35-4308-8e07-bb0eb8d950a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model predicts: 1\n",
      "The actual label is: 1\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random_index = random.choice(X_train.index)\n",
    "random_digit = X_train.loc[random_index]\n",
    "random_digit_label = Y_train.iloc[random_index]\n",
    "\n",
    "print(f'The model predicts: {clf.predict([random_digit])[0]}')\n",
    "print(f'The actual label is: {random_digit_label}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278eb449-4723-4e4a-86b1-a1730a769b4d",
   "metadata": {},
   "source": [
    "Under the hood the classifier above trained ten binary classifiers. One for each number 0-9. Then it computes the decision scores for each classifier and selects the maximum.\n",
    "\n",
    "This can be shown by calling `.decision_function()` instead of `.predict()`. This method returns the scores for all classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "991472db-f13c-4992-a141-f509dedc9885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-56564.39939804,  11770.5348058 ,  -5959.51606184,\n",
       "           320.87116003,  -9030.76209552,  -4090.43128662,\n",
       "         -5221.76959532, -13521.77270286,   -249.61173198,\n",
       "         -4374.4406201 ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.decision_function([random_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2f8293-4a8d-4468-a9bf-e7f595e128ac",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "\n",
    "Using **cross validation** I can assess the performance of a **predictive model**. <mark>It involves dividing the dataset into multiple subsets, training the model on some of these subsets, and testing it on others.</mark>\n",
    "\n",
    "KFold is a type of cross-validation where the dataset is divided into 'k' subsets or folds. The model is trained and tested 'k' times, each time using a different fold as the test set and the remaining folds as the training set. It helps to ensure that each data point is used for both training and testing at least once.\n",
    "\n",
    "StratifiedKFold is a variation of KFold that ensures that the class distribution in the original dataset is preserved in each fold.\n",
    "This is particularly important when dealing with imbalanced datasets where one class is much more frequent than the others.\n",
    "\n",
    "The latter is important. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c803152f-ffbf-42c0-ac34-d25779a27298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def cross_val(X, y, classifier):\n",
    "    # n_splits=3: how many times the dataset is split into training and testing sets\n",
    "    skfold = StratifiedKFold(n_splits=3, random_state=1337, shuffle=True)\n",
    "    \n",
    "    accuracies = []\n",
    "\n",
    "    for fold, (train_indices, test_indices) in enumerate(skfold.split(X, y)):\n",
    "        # Split the test data\n",
    "        X_train_folds, X_test_folds = X[train_indices], X[test_indices]\n",
    "        y_train_folds, y_test_folds = y[train_indices], y[test_indices]\n",
    "    \n",
    "        # Clone the classifier that was passed\n",
    "        clone_clf = clone(classifier)\n",
    "        clone_clf.fit(X_train_folds, y_train_folds)\n",
    "    \n",
    "        # Make predictions on the test data\n",
    "        y_pred_folds = classifier.predict(X_test_folds)\n",
    "    \n",
    "        # Calculate accuracy for this fold and store it\n",
    "        accuracy = accuracy_score(y_test_folds, y_pred_folds)\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "        print(f\"Fold {fold+1}: Accuracy = {accuracy:.2f}\")\n",
    "\n",
    "    # Calculate the average accuracy across all folds\n",
    "    average_accuracy = np.mean(accuracies)\n",
    "    print(f\"Average Accuracy: {average_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1181881c-49c6-4ccd-b2a4-8670c233b90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy = 0.88\n",
      "Fold 2: Accuracy = 0.88\n",
      "Fold 3: Accuracy = 0.88\n",
      "Average Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "cross_val(X_train.values, Y_train, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ebc6a0-0a2f-4be4-b534-54a907568c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(clf, X_train.values, Y_train, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e78b36f-465f-4f5e-9057-d4c827395529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
